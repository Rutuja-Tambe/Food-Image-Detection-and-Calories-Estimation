{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tw93\\OneDrive\\Desktop\\masters_project\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tw93\\OneDrive\\Desktop\\masters_project\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "Predicted class index: 9, Predicted label: fries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#with caloires\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.ops import nms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# model saving\n",
    "model_path = r'C:\\Users\\tw93\\OneDrive\\Desktop\\masters_project\\trained_model.keras'\n",
    "\n",
    "# Load the trained classification model\n",
    "classification_model = load_model(model_path)\n",
    "\n",
    "# Load a pre-trained object detection model\n",
    "detection_model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detection_model.eval()\n",
    "\n",
    "# Image dimensions for classification\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "channels = 1  \n",
    "\n",
    "#  preprocess the image for classification\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = img.reshape(1, img_height, img_width, channels)  \n",
    "    return img\n",
    "\n",
    "#  decode the predicted label\n",
    "def decode_label(label, label_encoder):\n",
    "    return label_encoder.inverse_transform([label])[0]\n",
    "\n",
    "\n",
    "classes = [\n",
    "    'apple', 'banana', 'bhatura', 'brownie', 'burger', 'cake',\n",
    "    'chapati', 'chole', 'dhokla', 'fries', 'grapes', 'gulabjamun',\n",
    "    'kababs', 'kadhipakoda', 'mango', 'meduvada', 'modak', 'noodles',\n",
    "    'pizza', 'pomogranate', 'rice', 'roll', 'samosa', 'strawberry',\n",
    "    'vadapav', 'watermelon'\n",
    "]\n",
    "\n",
    "\n",
    "calories = {\n",
    "    'apple': 52, 'banana': 96, 'bhatura': 277, 'brownie': 466, 'burger': 354,\n",
    "    'cake': 257, 'chapati': 104, 'chole': 164, 'dhokla': 152, 'fries': 312,\n",
    "    'grapes': 69, 'gulabjamun': 175, 'kababs': 250, 'kadhipakoda': 150,\n",
    "    'mango': 60, 'meduvada': 334, 'modak': 200, 'noodles': 138, 'pizza': 285,\n",
    "    'pomogranate': 83, 'rice': 130, 'roll': 300, 'samosa': 262, 'strawberry': 32,\n",
    "    'vadapav': 290, 'watermelon': 30\n",
    "}\n",
    "\n",
    "# fiiting lable encoder in the classes\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(classes)\n",
    "\n",
    "new_image_path = input(\"Enter the path to the image: \")\n",
    "new_image = preprocess_image(new_image_path)\n",
    "\n",
    "prediction = classification_model.predict(new_image)\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "# decoding predected label according to the class\n",
    "predicted_label = decode_label(predicted_class, label_encoder)\n",
    "print(f\"Predicted class index: {predicted_class}, Predicted label: {predicted_label}\")\n",
    "\n",
    "#  detect objects in an image\n",
    "def detect_objects(image_path, model, threshold=0.5):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    image_tensor = transform(image)\n",
    "    with torch.no_grad():\n",
    "        predictions = model([image_tensor])\n",
    "        \n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    \n",
    "    # reducing the not required bounding boxes\n",
    "    keep = nms(torch.tensor(boxes), torch.tensor(scores), iou_threshold=0.3)\n",
    "    boxes = boxes[keep].astype(int)\n",
    "    scores = scores[keep]\n",
    "\n",
    "    valid_boxes = []\n",
    "    valid_labels = []\n",
    "\n",
    "    # Filter boxes based on threshold\n",
    "    for idx, box in enumerate(boxes):\n",
    "        if scores[idx] >= threshold:\n",
    "            valid_boxes.append(box)\n",
    "            valid_labels.append(predicted_label)\n",
    "\n",
    "    return image, valid_boxes, valid_labels\n",
    "\n",
    "# draw boxes around detected objects\n",
    "def draw_boxes(image, boxes, labels):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)  \n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()  \n",
    "\n",
    "    for box, label in zip(boxes, labels):\n",
    "        calorie_info = calories.get(label, \"Unknown\")\n",
    "        text = f\"{label} ({calorie_info} calories)\"\n",
    "        draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=\"red\", width=3)\n",
    "        draw.text((box[0], box[1] - 10), text, fill=\"blue\", font=font)\n",
    "    return image\n",
    "\n",
    "image, detected_boxes, detected_labels = detect_objects(new_image_path, detection_model)\n",
    "image_with_boxes = draw_boxes(image, detected_boxes, detected_labels)\n",
    "image_with_boxes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
