{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Boxes: tensor([[ 29.0447,  27.3501, 195.1044, 219.6239]])\n",
      "Filtered Labels: tensor([53])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (1, 128, 128, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 128, 128, 3), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Input image path\u001b[39;00m\n\u001b[0;32m    114\u001b[0m new_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the path to the image: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 115\u001b[0m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_image_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 94\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered Boxes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiltered_boxes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered Labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiltered_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m detected_labels \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected Classes and Total Calories:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m total_calories \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[3], line 79\u001b[0m, in \u001b[0;36mclassify_objects\u001b[1;34m(image_path, boxes)\u001b[0m\n\u001b[0;32m     77\u001b[0m crop \u001b[38;5;241m=\u001b[39m crop\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     78\u001b[0m crop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(crop, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m predicted_class_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     81\u001b[0m predicted_class_label \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform([predicted_class_index])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tw93\\OneDrive\\Desktop\\masters_project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\tw93\\OneDrive\\Desktop\\masters_project\\env\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (1, 128, 128, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 128, 128, 3), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.ops import nms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torchvision.transforms as T\n",
    "from skimage import feature  \n",
    "import pickle\n",
    "\n",
    "\n",
    "model_path = r'C:\\Users\\tw93\\OneDrive\\Desktop\\masters_project\\trained_model.keras'\n",
    "classification_model = load_model(model_path)\n",
    "\n",
    "\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "calories = {\n",
    "    'apple': 52, 'banana': 96, 'bhatura': 300, 'brownie': 466, 'burger': 295,\n",
    "    'chapati': 68, 'chole': 164, 'dhokla': 160, 'gulabjamun': 175,\n",
    "    'kababs': 197, 'mango': 60, 'meduvada': 135, 'modak': 108,\n",
    "    'pizza': 266, 'pomogranate': 83, 'rice': 130, 'samosa': 262, 'strawberry': 33,\n",
    "    'vadapav': 300, 'watermelon': 30\n",
    "}\n",
    "\n",
    "\n",
    "detection_model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detection_model.eval()\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path, img_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    else:\n",
    "        raise ValueError(f\"Image not found or unable to read: {image_path}\")\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        detections = detection_model(image_tensor)[0]\n",
    "    return detections, image\n",
    "\n",
    "def filter_detections(detections, score_threshold=0.5, iou_threshold=0.3):\n",
    "    boxes = detections['boxes']\n",
    "    scores = detections['scores']\n",
    "    labels = detections['labels']\n",
    "    keep = nms(boxes, scores, iou_threshold)\n",
    "    filtered_boxes = boxes[keep][scores[keep] > score_threshold]\n",
    "    filtered_labels = labels[keep][scores[keep] > score_threshold]\n",
    "    return filtered_boxes, filtered_labels\n",
    "\n",
    "def draw_boxes(image, boxes, labels):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box, label in zip(boxes, labels):\n",
    "        draw.rectangle(box.tolist(), outline='red', width=3)\n",
    "        draw.text((box[0], box[1]), str(label), fill='red')\n",
    "    return image\n",
    "\n",
    "def classify_objects(image_path, boxes):\n",
    "    detected_labels = []\n",
    "    for box in boxes:\n",
    "        crop = cv2.imread(image_path)[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "        if crop.size > 0:\n",
    "            crop = cv2.resize(crop, (128, 128))\n",
    "            crop = crop.astype('float32') / 255.0\n",
    "            crop = np.expand_dims(crop, axis=0)\n",
    "            prediction = classification_model.predict(crop)\n",
    "            predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "            predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "            \n",
    "            # Ensure the predicted label is a food item\n",
    "            if predicted_class_label in calories:\n",
    "                detected_labels.append(predicted_class_label)\n",
    "    \n",
    "    return detected_labels\n",
    "\n",
    "def process_image(image_path):\n",
    "    detections, image = detect_objects(image_path)\n",
    "    filtered_boxes, filtered_labels = filter_detections(detections)\n",
    "    print(f\"Filtered Boxes: {filtered_boxes}\")\n",
    "    print(f\"Filtered Labels: {filtered_labels}\")\n",
    "    detected_labels = classify_objects(image_path, filtered_boxes)\n",
    "\n",
    "    print(\"Detected Classes and Total Calories:\")\n",
    "    total_calories = {}\n",
    "    for label in detected_labels:\n",
    "        if label in total_calories:\n",
    "            total_calories[label] += calories.get(label, 0)\n",
    "        else:\n",
    "            total_calories[label] = calories.get(label, 0)\n",
    "\n",
    "    for label, cal in total_calories.items():\n",
    "        print(f\"{label}: {cal} calories\")\n",
    "\n",
    "    total_calories_sum = sum(total_calories.values())\n",
    "    print(f\"Total calories present in the image: {total_calories_sum} calories\")\n",
    "\n",
    "    image_with_boxes = draw_boxes(image, filtered_boxes, detected_labels)\n",
    "    image_with_boxes.show()\n",
    "\n",
    "# Input image path\n",
    "new_image_path = input(\"Enter the path to the image: \")\n",
    "process_image(new_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
